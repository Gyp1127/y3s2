# The Biological Neuron
<details>
  <summary>1. What is the primary function of dendrites in a neuron?</summary>
  Dendrites receive signals from other neurons and conduct these signals to the cell body.
  </details>

<details>
  <summary>2. Which structure is responsible for insulating the axon and speeding up neural impulses?</summary>
  The Myelin sheath insulates the axon and helps speed up the transmission of neural impulses.
  </details>

<details>
  <summary>3. What is the role of the synapse in neuronal communication?</summary>
  The synapse is the junction between two neurons where neurotransmitters are released to transmit signals from one neuron to another.
  </details>

# Neuronal Computation
<details>
  <summary>1. How does computation in neural networks differ from traditional computer architectures?</summary>
  Computation in neural networks occurs in parallel across large numbers of very simple processing units, while traditional computer architectures process in a serial fashion.
</details>

<details>
  <summary>2. How is information distributed in a neural network?</summary>
  Information is distributed across the entire network rather than being located in one specific place or address.
</details>

<details>
  <summary>3. What is Parallel Distributed Processing?</summary>
  It is the method where computation occurs in parallel across many processing units, and information is distributed throughout the network.
</details>

<details>
  <summary>4. Describe the Single Layer Feedforward Network.</summary>
  The input units are set and activation propagates through the network until the values of the output units are determined. It acts as a vector-valued function taking one vector on the input and returning another on the output.
</details>

<details>
  <summary>5. In a Single Layer Feedforward Network, what might the inputs and outputs represent?</summary>
  The inputs might represent the characteristics of an object and the output might indicate which object is currently being viewed.
</details>

<details>
  <summary>6. Why might an extra hidden layer be needed in a network?</summary>
  Some problems are not solvable with single layer networks, so an extra hidden layer is added to allow the network to create its own representation of the inputs.
</details>

<details>
  <summary>7. What is the Universal Approximation Theorem in the context of Multi Layer Feedforward Networks?</summary>
  Given enough hidden units of the right kind, it is possible to approximate almost any function arbitrarily closely.
</details>

<details>
  <summary>8. Describe the Fully Recurrent Network.</summary>
  Patterns are instantiated on the units one at a time, modifying the weights. A degraded version of one pattern is presented, and the network can reconstruct the pattern.
</details>

<details>
  <summary>9. What does degradation in the context of the Fully Recurrent Network mean?</summary>
  Degradation might mean part of the pattern is missing, like when an object is occluded, or it is noisy due to interference with the memory trace.
</details>

<details>
  <summary>10. How does the Competitive Network differ from the Single Layer Feedforward Network?</summary>
  The competitive network has connections, usually negative, between the output nodes which make the output nodes compete to represent the current input pattern.
</details>

<details>
  <summary>11. What is the significance of the Competitive Network in human sensory systems?</summary>
  Networks of this kind have been used to explain the formation of topological maps in many human sensory systems, including vision, audition, touch, and smell.
</details>

<details>
  <summary>12. What makes recurrent networks unique in processing?</summary>
  Their processing depends on the state of the network at the last timestep, allowing them to respond to the current input differently based on previous inputs. They have a kind of short-term memory.
</details>

<details>
  <summary>13. Name two examples of Other Recurrent Networks.</summary>
  Simple Recurrent Network and the Jordan Network.
</details>

<details>
  <summary>14. Why do computer scientists and engineers find neural networks appealing?</summary>
  Neural networks provide a paradigm for solving problems which is often very successful, especially in domains that are poorly understood or subject to great uncertainty.
</details>

<details>
  <summary>15. How do neural networks serve as a metaphor for cognitive scientists, linguists, psychologists, and philosophers?</summary>
  They provide a metaphor for understanding cognitive processes such as perception, attention, learning, memory, language, reasoning, and thinking.
</details>

<details>
  <summary>16. Why are neural networks beneficial for neuroscientists?</summary>
  The mathematical simplification of physiological processes allows for the analysis of large networks of units, providing insight into how neuron interactions result in overt behaviour.
</details>

<details>
  <summary>17. What does a Multi Layer Feedforward Network use to create its own representation of inputs?</summary>
  An extra hidden layer.
</details>

<details>
  <summary>18. How is information processed in the Single Layer Feedforward Network?</summary>
  Activation is propagated through the network until the values of the output units are determined.
</details>

<details>
  <summary>19. In the Competitive Network, what effect do the connections between output nodes have?</summary>
  Because of these connections, the output nodes tend to compete to represent the current input pattern.
</details>

<details>
  <summary>20. What kind of memory do recurrent networks possess?</summary>
  They have a kind of short term memory.
</details>
